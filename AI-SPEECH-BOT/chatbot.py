import numpy
import tensorflow
import tflearn
import random
import nltk
from nltk.stem.lancaster import LancasterStemmer


stemmer = LancasterStemmer()

data={"intents": [
        {"tag": "AssertionError",
         "patterns": ["assertion statement fails","assertion error", "assertion failing", "can't find assertion","assert statement fails", "assert failing", "can't find assert"],
         "responses": ["AssertionError - An AssertionError is an error generated by the program to indicate that something that should never happen, has happened. It is commonly used in the method of 'defensive programming' where we check all the time to make sure that the state of the program and it's inputs and outputs are correct."],
         "context_set": ""
        },
        {"tag": "EOFError",
         "patterns": ["the input() function hits the end-of-file condition","eof error","end of file error", "EOF condition", "EOF", "end of file"],
         "responses": ["EOFError- This specific error means the file mentioned in the error message ends abruptly without the proper closing tags, and the code was unable to be parsed as a result."],
         "context_set": ""
        },
        {"tag": "IndexError",
         "patterns": ["index of sequence out of range","index error", "can't index propoerly", "indexing failed", "can't sequence properly","index out of boud","cannot find index properly"],
         "responses": ["IndexError- An IndexError is raised when a sequence reference is out of range.The given code is rewritten as follows to catch the exception and find its type"],
         "context_set": ""
        },
        {"tag": "Memory Error",
         "patterns": ["code runs out of memory","memory error","cannot find proper space to operate", "operation runs out of memory", "operation runs out of space"],
         "responses": ["Memory Error- A memory error means that your program has run out of memory. This means that your program somehow creates too many objects. In your example, you have to look for parts of your algorithm that could be consuming a lot of memory. If an operation runs out of memory it is known as memory error."],
         "context_set": ""
        },
        {"tag": "Syntax Error",
         "patterns": ["syntax cannot be matched", "no proper syntax", "syntax error", "syntax error is encountered"],
         "responses": ["Syntax Error- A syntax error is an error in the source code of a program. Since computer programs must follow strict syntax to compile correctly, any aspects of the code that do not conform to the syntax of the programming language will produce a syntax error"],
         "context_set": ""
        },
        
   ]
}

words = []
labels = []
docs_x = []
docs_y = []
for intent in data['intents']:
    for pattern in intent['patterns']:
        wrds = nltk.word_tokenize(pattern)
        words.extend(wrds)
        docs_x.append(wrds)
        docs_y.append(intent["tag"])
        
    if intent['tag'] not in labels:
        labels.append(intent['tag'])

words = [stemmer.stem(w.lower()) for w in words if w != "?"]
words = sorted(list(set(words)))

labels = sorted(labels)
training = []
output = []

out_empty = [0 for _ in range(len(labels))]



for x, doc in enumerate(docs_x):
    
    bag = []
    
    wrds = [stemmer.stem(w.lower()) for w in doc]

    
    for w in words:
        if w in wrds:
            bag.append(1)
        else:
            bag.append(0)

    
    output_row = out_empty[:]
    output_row[labels.index(docs_y[x])] = 1
    
    training.append(bag)
    output.append(output_row)
    
tensorflow.reset_default_graph()

net = tflearn.input_data(shape=[None, len(training[0])])
net = tflearn.fully_connected(net, 8)
net = tflearn.fully_connected(net, 8)
net = tflearn.fully_connected(net, len(output[0]), activation="softmax")
net = tflearn.regression(net)

model = tflearn.DNN(net)

model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)
model.save("log/model.tflearn")

def bag_of_words(s, words):
    bag = [0 for _ in range(len(words))]

    s_words = nltk.word_tokenize(s)
    s_words = [stemmer.stem(word.lower()) for word in s_words]

    for se in s_words:
        for i, w in enumerate(words):
            if w == se:
                bag[i] = 1
            
    return numpy.array(bag)


# def chat():
#     print("Start talking with the bot (type quit to stop)!")
#     while True:
#         inp = input("You: ")
#         inp=inp.lower()
#         if inp == "quit":
#             break
#
#         results = model.predict([bag_of_words(inp, words)])[0]
#         results_index = numpy.argmax(results)
#
#         tag = labels[results_index]
#
#         if results[results_index] > 0.7:
#
#             for tg in data["intents"]:
#                 if tg['tag'] == tag:
#                     responses = tg['responses']
#
#             print(random.choice(responses))
#         else:
#             print("I didn't get that plz try again")
#
# #chat()
